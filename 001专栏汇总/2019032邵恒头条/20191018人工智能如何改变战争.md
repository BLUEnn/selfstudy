# 105 | 人工智能如何改变战争？
> 邵恒头条
2019-10-18

这两天，土耳其出兵叙利亚的新闻，引发了不少关注。有很多人认为，这场武装冲突之所以会爆发，有一个不可忽视的原因，那就是特朗普让美国军队从叙利亚撤兵，而且还默许土耳其出兵。美国政府官员，对特朗普撤兵的决定也颇有微词。

那撤兵到底对还是不对呢？不知道。因为我们谁都不清楚，特朗普手里到底有什么信息，让他做出了这样的决定。也许他就是看了福克斯新闻，拍脑袋决定的，也许他认真听取了对于叙利亚局势的详细军事情报，仔细斟酌后才作出的决定。

但有一件事恐怕很多人都有感知，那就是在这个时代，很多时候做决策已经不仅仅是靠人了。在各种场景下，通过科技能收集到的数据越来越多，一个人要做决策，面对的信息复杂度越来越高。也许只有在人工智能的辅助下，才能化繁为简，形成最优策略。

这件事，在军事领域其实就正在发生。

前段时间，《经济学人》发表了一篇长文，叫做「战争的算法」。这篇文章分享的诸多案例让我意识到，人工智能正在改变军事决策的方方面面。

今天的《邵恒头条》，就来跟你分享一下这篇文章的观点。

我之所以会关注这个话题，是因为今年 2 月，美国国防部对外发布了有史以来第一份人工智能战略文件。在这份文件里他们说了一个值得关注的判断：人工智能已经准备好了，随时可能会改变未来的战场。

当时我就开始好奇了，到底怎么个改变法呢？《经济学人》的这篇文章，恰好提供了不少细节。比如说，情报。

我们都知道，情报一直都是在战争当中制胜的关键因素。但其实，在战场上，难的不一定是获取情报，而是从情报中挖掘有价值的信息。现在，能用来收集情报的设备已经非常多了，卫星、侦察机，甚至是手机、电脑设备。这些设备提供的海量数据怎么处理，才是真正的问题。

比如说，在 2011 年，美国光是靠无人机获取的影像，就有 327000 个小时，也就是大约 37 年的影像。这么多影像，光靠人眼看，那肯定是处理不过来的。

人工智能算法，恰恰就能用来处理这样的数据。4 年前，实验室里的图像分类算法，就已经超越了人类的表现。到了 2018 年，用算法已经可以做到，从一张图里找出很多个不同的物体并且把它们进行分类。

基于这样的技术，美国国防部就在前两年成立了一个叫做「算法战争」的团队。这个团队的工作就是要利用深度学习算法，从战地的影像里发现可疑的行为。

当然，算法能处理的不仅是图像数据。还记得斯诺登泄露的美国「天网」计划么？这项计划的一部分，是监督可疑人士的通讯记录。这个项目里就用上了人工智能来分析恐怖分子的情报。

比如，在巴基斯坦地区，谁在过去的一个月里从拉合尔去过边境城镇白沙瓦？谁比平时更频繁地关闭手机或者更换手机设备？这些都是储存在手机端的一些零碎信息，量很大又很容易被忽略。而美国会把这些数据用机器学习进行处理，然后用算法判断出，谁可能是给恐怖组织传信的人。

假如没有人工智能，这些信息就算摆在眼前，恐怕也难以从中剔除出有效情报。可以说，算法让战场上的信息，变得更加透明了。

不过，说到这，咱们还只是讲了算法在军事行动当中最基础的应用，充当情报员。但如果人工智能会思考，那肯定不甘心只当情报员，一定会想在军队的权力架构里往上爬，比如说，帮助指挥官制定战略，做出军事决策。

在今天，往这个方向努力的人工智能公司，可不在少数。

文章里介绍了一家叫做「北方之箭」的以色列公司。这家公司就能通过处理大量的数据，帮助指挥官部署战斗。这些数据通常包括敌方位置、武器类型、地理位置和天气状况等等信息。另外算法还会综合考虑以往的经验数据，给出不同的决策选项。

这种工作要是让人做，那得看地图、看表格、做各种分析，一般来说得花上十几、二十个小时才能完成。文章里虽然没说北方之箭做得有多快，但猜都能猜到，一定节省了不少时间。

除此之外，人工智能做决策，还有一种模式，就是在一个仿真的战争环境里运行算法。英国的国防部购买了一个由游戏公司开发的软件，用来模仿复杂的操作环境，各种真实环境的数据都可以输入进去被人工智能算法处理。

从这些案例来看，战争「智能化」似乎已经是必然的趋势。国防大学的教授李明海在一篇评论里，曾经把「智能化战争」的未来机制总结得很清楚。他说未来的战争会成为「算法博弈」，由「机器主战」，从「人脑决策」向「智能决策」转变。

如果你想感受一下，这样的战争是什么样的，那你可以看一下 1970 年。在那年的一场军事行动里，很多人对未来战争的想象其实已经成为现实了。

这场战争是越南战争，这次军事行动的代号是「白色冰屋」。

当时美军利用海军战机，在越南的丛林里投放了一些电子监听设备。比如麦克风，用来监听敌军脚步声或者卡车点火声，再比如嗅觉传感器，可以嗅出人类尿液中的氨，追踪敌军的行踪。这些数据被传导到无人机和电脑上，算法处理后，就会生成投放炸弹的区域。几分钟之内，战机就会根据算法的指令起飞。

之所以说这场军事行动，是未来战争的缩影，是因为它恰好展现了人工智能参与到军事行动当中的每一个环节：从收集情报、到处理情报，再到做出轰炸决策。

不过，智能化的战争形态，从实际操作和伦理层面考虑，也有不少值得担忧之处。其中最大的隐患，恐怕就是可解释性。

我们都知道，深度学习就像是一个黑盒子，它为什么会做出一个决策，自己都无法解释。假如深度学习算法被用到战争决策当中，我们又怎么能理解一个决策背后的合理性呢？

人总认为自己是最有智慧的，但也许算法比我们看得更全面，考虑得更长远呢？当算法的决策和人的决策冲突，而人又无法理解决策背后的理由时，到底应该相信谁呢？

好了，总结一下。在今天的《邵恒头条》中，我为你介绍了战争智能化的趋势。人在战争中的决策权，可能会逐步让渡给算法。未来战争的形式可能会因此发生天翻地覆的变化。

不过，有一个不可忽视的事实是，就算算法能做决策，它也无法帮助人类承担决策的后果。所以，我认为最适合算法的位置，还是充当人类的军师。因为算法再先进，战争也是人类的政治活动。

