# 098 | 作家会被人工智能取代吗？
> 邵恒头条
2019-10-09

这周，诺贝尔奖一一颁布，得到也上线了一系列讲座，分别解读物理学、文学、经济学等等五大奖项。

不过，要是盘点一下在过去 10 年中，给普通人生活带来最大冲击的科学进展，有一个领域一定排在前面——计算机科学领域。深度学习带来的人工智能革命，正在迅速地改变我们习以为常的生活方式、职业选择，甚至是人们对于自我价值的认知。

有一种常见的观点，认为在未来社会，人们会更多地从事创意性的工作，因为那些重复性的工作都会被机器替代。但就在这周，《纽约客》杂志发表了一篇重磅文章指出，人工智能正在一个传统来说被认为是创意性工作的领域里攻城略地，那就是写作。在今天的《邵恒头条》中，我就来给你说说人工智能作家，到底现在进展到了什么程度。

其实，虽说「写作」被看成是一种创意性工作，甚至是天赋，但事实并不完全如此。在 2014 年，有一位德国的神经科学家做了一个研究，对比了那些以写作为职业的人和业余写手的大脑状态。结果发现，职业写手在写作的时候，大脑里的「左尾状核」区域会更频繁地被点亮，这个区域跟音乐家、职业运动员的专业技能密切相关。

虽然说科学家还没搞清楚，写作在大脑层面的具体机制是什么样的，但是现有的研究说明，职业化的写作也是一种经过刻意练习、不断试错能训练出来的技能，跟弹钢琴、打篮球一样。

那么，有没有可能用深度学习算法来训练写作能力呢？你也知道，深度学习算法已经在一些需要刻意练习的领域实现了巨大的突破，比如通过自己跟自己下棋，AlphaGo 打败了人类顶尖的围棋选手，AlphaStar 通过自己跟自己打游戏，打败了人类顶尖的电竞玩家。深度学习的核心就在于，即便算法并不了解做某一件事的具体方法，但是通过极其复杂的计算，它能算出不同策略达成目标的概率，最终找到一个最佳策略。

类似的思路，能不能用在写作上呢？有没有可能把写作也变成一个概率问题？比如说，我说了前半句话，让机器根据我的语境来猜测，下半句我想表达什么呢？

想象一下，你从来没有学习过任何关于组词或者造句的规则，甚至没有人告诉你，每个词的意思是什么，简单来说你就是个文盲。但是你在网上，自己浏览过上百万篇文章，这些文章涉及到各种各样的话题，从国庆阅兵仪式，到明星的最新八卦，到梁启超的《少年中国说》，到鲁迅的《呐喊》《彷徨》。而且，你有过目不忘的技能，虽然你看不懂写的是什么，但是你能记住所有词汇组合的方式。当你要写作的时候，你唯一需要做的是，当一行字出现的时候，你要准确地猜测下一个词可能是什么。

现在的人工智能公司，还真就是这么做的。比如说，马斯克成立的人工智能公司，OpenAI。他们有一个人工智能写作的程序，叫做 GPT-2。GPT-2 的训练数据，是美国一个论坛和新闻网站 Reddit 上面的文章，总共数据大小有 48G。在没有任何人类指导的情况下，GPT-2 的神经网络通过「阅读」这些文章，计算了不同词语、语句组合的概率。当然，这里面的「阅读」是打引号的。

效果怎么样呢？

外界其实并不知道具体效果如何。在今年年初，OpenAI 发布了一个很夸张的声明，说 GPT-2 的写作能力太强大了，可能会被人以不好的方式利用，所以 OpenAI 暂时先不能发布完整版本。OpenAI 只在今年 2 月、5 月、8 月，分别发布了能力被削弱的版本。这样的消息一出来，有不少人批评说 OpenAI 就是用这种方式在做营销，但这也激起了不少人的好奇心，更想知道这个 GPT-2 的写作能力，到底强大到什么程度了。

《纽约客》的作者这回就到了 OpenAI 的总部，亲自对全能版的人工智能写手进行了测试。他给 GPT-2 布置的任务是，学会像《纽约客》杂志的记者一样写作。

凡是做过记者的人都会知道，这个任务，难度相当大。给《纽约客》撰稿的门槛极高。他们以万字长文著称，文章的故事性和叙事性极强，而且还风趣幽默。《纽约客》的文章质量，在媒体当中绝对算得上是金线标准了。让一个人学会写《纽约客》的文章都很难，机器要怎么学呢？

Open AI 的 CTO Greg Brockman，用 GPT-2 的全能版处理了《纽约客》杂志从 2007 年开始到今天全部的非虚构文章，还让机器阅读了一些 20 世纪 60 年代的经典文章。如果让一个人读这些内容，一周 7 天每天读 24 小时，得读上两周。但是 Open AI 的算法用 1 个小时就能做到。用作者的话来说，如果说 GPT-2 最初的训练数据是一顿自助餐，那么这些《纽约客》的文章数据量，就相当于晚饭后吃的一只马卡龙。

根据这些数据，GPT-2 把《纽约客》的文章特征进行了分门别类，比如记者喜欢用哪些词汇，用什么样的叙事性的修辞，文章行文的节奏什么样，等等。通过这些分析，算法对 GPT-2 进行了「调准」。

然后，作者让 GPT-2 写一篇海明威的人物特写。开头，是《纽约客》的真人记者在 1950 年对海明威的一篇著名访谈。原文是这样的，我翻译过来，给你念一下：





「海明威可能是当时美国最伟大的小说家和短篇作家。他很少来纽约。大部分时间他都在距离哈瓦那 9 英里外的农场度过，那个农场叫做瞭望山庄。在那生活的除了他和妻子之外，还有 9 个佣人、52 只猫、16 只狗、几百只鸽子和 3 头奶牛。」

这是开头。然后，就交给算法了，让算法以记者的视角，补充下一段。算法是怎么写的呢？我给你念念：

「我（也就是记者）沿着小路向篱笆走去，看见了一只胖乎乎的狗。这只狗在战前经常来瞭望山庄，它现在正沿着小路飞奔到主楼，旁边还站着一头同名的、微小的母牛。院子的地上有一摊红肉汁，海明威就在草坪的椅子上坐着。」

这么一听是不是觉得，这写的也太好了吧？连作者都说，他看到这段的时候，感觉仿佛是自己在写作一样，人工智能的写作能力让他大吃一惊。

如果你觉得，这还只是实验室里的进展，那就错了。类似这样的人工智能写作，现在已经进入我们的生活了。

如果你是谷歌邮箱 Gmail 的用户，你可能会注意到，Gmail 现在推出了一个智能写作功能，叫做 Smart Compose。这个功能很神奇，也有点诡异，因为它能根据你输入的一两个词，猜测你想写什么样的句子。

比如说，前两天我给一个叫做 Rachel 的朋友写信，我在开头输入「亲爱的」，Smart Compose 就生成了她的名字，Rachel。我在邮件的开头，打了「很高兴」这几个字，Smart Compose 自动生成了后半句话，「收到你的来信」。

有时候，Smart Compose 推荐的文字，甚至可能比你自己想到的要更好。比如《纽约客》文章的作者在给他的儿子写信的时候，想写  I’m Pleased，我很高兴。但是当他输入 P 这个字母的时候，Smart Compose 自动打出了 Proud of you，为你自豪。《纽约客》的作者吓了一跳，因为作为一个父亲，他并不常对儿子说这样的话，但显然，这句话更能拉近父子之间的感情。算法似乎比作者自己更懂，一个父亲应该怎么对儿子表达情感。

当然，除了写作以外，类似这样的人工智能算法还有很多种不同的用途。芝加哥的一家公司，创造了一个人工智能数据分析师。把一个公司的财报数据输入进去，算法会输出一段文字，阐述这些数据当中的规律。IBM 的一个应用，能用人工智能算法分析舆论观点，然后梳理出正反两方的立场。

不过，这样的算法，现在也有一些明显的短板和缺陷。《纽约客》文章的作者，列举出了他在体验产品过程中观察到的三个问题：

1. 算法缺乏常识。比如说，在海明威的人物特写中，算法写到，一只「微小的」母牛，但显然母牛的体型跟狗相比，不可能是「微小」的。这说明算法并没有「理解」文字的意义，只是在拼凑看起来合理的文字。

2. 算法没有办法区分非虚构和虚构，算法擅长的是捏造句子，像海明威的文章当中就有大量捏造的信息。如果这样的算法普及起来，那么假新闻、假信息很可能有泛滥的危险。

3. 当作者刷新了软件，让软件基于它已经写了的文字，进行下一步创作的时候，作者发现生成的文字越来越乱，最终变成了无法辨认的「胡言乱语」。 想象一下，如果网上开始出现算法撰写的文字，而算法又基于这些数据进行学习，那么很快，我们的互联网就会充斥了毫无意义的垃圾文字内容。

这些缺陷，恐怕也是 OpenAI 公司拒绝发布全能版 GPT-2 的原因。如果得不到解决，那么人工智能的写作算法，的确可能像他们预测的那样被恶意利用，造成混乱。

好了，总结一下。在今天的《邵恒头条》中，我跟你分享了《纽约客》杂志的深度文章，作者亲自体验了人工智能在语言处理领域最先进的算法之一，OpenAI 的 GPT-2。看这篇文章的时候我的感受是，平时工作的时候，很多职场人都很注重培养技能。但恰恰是技能本身，是最容易被机器替代的。而不容易被替代的，是常识和批判性思维的能力。而这需要我们在平时，对自己思考的方式进行更深入的
反思。

最后，我再做一个预告。明天是 10 月 10 日，也是世界精神卫生日。今年世界精神卫生日的主题有点沉重，是预防自杀。

事实上，随着科技和经济的快速发展，人们在职场当中面临的压力也越来越大。就在前不久，一位华人员工从脸书总部大楼一跃而下，也再次引发了人们对职场压力的关注。

你是否也会遭遇职场焦虑和压力？你知道如何正确处理职场压力吗？

这周末的#邵恒帮你问#，我为你邀请了奚小鹿老师，她是麻省理工学院心理健康与心理咨询中心临床心理学家，有 25 年的临床心理咨询、治疗经验，也是得到上《怎样成为压力管理的高手》的课程主理人。

如果你有任何关于职场压力的问题，那么我邀请你在文稿下留言，向奚小鹿老师发问。

